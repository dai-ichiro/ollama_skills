import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

import gradio as gr
from langgraph.prebuilt import create_react_agent
from langchain_ollama import ChatOllama
from skill_loader import SkillLoader, create_state_modifier_from_skills

print("ğŸ”§ ã‚¹ã‚­ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")

# ã‚¹ã‚­ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’åˆæœŸåŒ–
loader = SkillLoader(skills_base_dir="./skills/skills")
skills = loader.load_skills(["pdf"])

# ãƒ„ãƒ¼ãƒ«ã‚’é›†ç´„
all_tools = []
for skill in skills:
    all_tools.extend(skill["tools"])
    print(f"âœ“ {skill['name']} skill: {len(skill['tools'])} tools")

# ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
skill_instructions = create_state_modifier_from_skills(skills)

# ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆä½œæˆ
llm = ChatOllama(model="ministral-3")
agent = create_react_agent(llm, all_tools)

print(f"âœ… ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæº–å‚™å®Œäº† ({len(all_tools)} ãƒ„ãƒ¼ãƒ«)")


def extract_text_content(msg_dict):
    """Gradio 6å½¢å¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º"""
    content = msg_dict.get("content", "")

    # content ãŒãƒªã‚¹ãƒˆå½¢å¼ã®å ´åˆï¼ˆGradio 6ã®æ§‹é€ åŒ–å½¢å¼ï¼‰
    if isinstance(content, list):
        text_parts = []
        for item in content:
            if isinstance(item, dict) and item.get("type") == "text":
                text_parts.append(item.get("text", ""))
        return " ".join(text_parts)

    # content ãŒæ–‡å­—åˆ—ã®å ´åˆï¼ˆå˜ç´”ãªå½¢å¼ï¼‰
    return str(content)


def process_message_stream(message):
    """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰"""
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
    messages = [
        {"role": "system", "content": skill_instructions},
        {"role": "user", "content": message}
    ]

    # ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
    try:
        accumulated_response = ""
        for chunk in agent.stream({"messages": messages}, stream_mode="values"):
            last_msg = chunk["messages"][-1]

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹ã‚’å–å¾—
            if hasattr(last_msg, 'content'):
                content = last_msg.content

                # ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
                if content and isinstance(content, str):
                    accumulated_response = content
                    yield accumulated_response

    except Exception as e:
        error_msg = f"**ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ:**\n\n```\n{str(e)}\n```"
        yield error_msg


# Gradio UIï¼ˆå·¦å³åˆ†å‰²ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰
with gr.Blocks(title="LangGraph Agent") as demo:
    gr.Markdown("# ğŸ¤– LangGraph Agent with Claude Skills")
    gr.Markdown(f"**PDFã‚¹ã‚­ãƒ«æ­è¼‰** - {len(all_tools)}å€‹ã®ãƒ„ãƒ¼ãƒ«ãŒåˆ©ç”¨å¯èƒ½")

    with gr.Row():
        # å·¦å´ï¼šå…¥åŠ›ã‚¨ãƒªã‚¢
        with gr.Column(scale=1):
            input_text = gr.Textbox(
                label="å…¥åŠ›",
                placeholder="ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...",
                lines=10
            )
            submit_btn = gr.Button("å®Ÿè¡Œ", variant="primary")
            clear_btn = gr.Button("ã‚¯ãƒªã‚¢")

            gr.Markdown("### ã‚µãƒ³ãƒ—ãƒ«")
            gr.Examples(
                examples=[
                    ["/home/hoge/ollama_skills/chapter_1.pdfã‚’PNGç”»åƒã«å¤‰æ›ã—ã¦"],
                    ["PDFã®å‡¦ç†æ–¹æ³•ã‚’æ•™ãˆã¦"],
                    ["åˆ©ç”¨å¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚’æ•™ãˆã¦"],
                ],
                inputs=input_text,
            )

        # å³å´ï¼šå‡ºåŠ›ã‚¨ãƒªã‚¢
        with gr.Column(scale=1):
            output_md = gr.Markdown(label="å‡ºåŠ›", value="ã“ã“ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

    # ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
    def on_submit(message):
        if not message.strip():
            yield "**å…¥åŠ›ãŒç©ºã§ã™ã€‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚**"
            return

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†
        for response in process_message_stream(message):
            yield response

    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚’æœ‰åŠ¹ã«ã—ã¦æ¥ç¶š
    submit_btn.click(on_submit, inputs=input_text, outputs=output_md)
    input_text.submit(on_submit, inputs=input_text, outputs=output_md)
    clear_btn.click(lambda: ("", "ã“ã“ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™"), outputs=[input_text, output_md])

if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸš€ Gradioã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¾ã™...")
    print("="*60 + "\n")
    demo.launch()
